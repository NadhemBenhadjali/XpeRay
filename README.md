# XpeRay: Vision-Language Radiology Report Generation

**XpeRay** is a vision-language model fine-tuned using Unsloth's `FastVisionModel` based on the `LLaMA-3.2-11B-Vision-Instruct` (4-bit) architecture. It is designed to generate detailed, accurate radiology reports from medical images.

## Features

- Vision-language fine-tuning for clinical image-to-text generation
- Uses LoRA with 4-bit quantization for efficient training
- Compatible with gradient checkpointing and Flash Attention 2
- Evaluation using K-Fold cross-validation with BLEU, ROUGE, and BERTScore
- Efficient model deployment and local inference

## Directory Structure

```
XpeRay/
‚îÇ
‚îú‚îÄ‚îÄ Model/                # Directory containing saved fine-tuned model
‚îú‚îÄ‚îÄ training.py            # Fine-tuning script using Unsloth and Hugging Face
‚îú‚îÄ‚îÄ inference.py           # Inference script to generate radiology reports
‚îú‚îÄ‚îÄ test.py                # Evaluation script with K-Fold validation
‚îú‚îÄ‚îÄ results.txt            # Evaluation results summary
‚îú‚îÄ‚îÄ visualization.py       # to analyse results.txt and extract curves

````
## üß† Model Weights

The model weights are **not included** in this repository due to GitHub file size limitations.

üëâ To use the model, please **download the `adapter_model.safetensors` file from Kaggle**:

üîó [XpeRay Model on Kaggle](https://www.kaggle.com/models/nadhembenhadjali/xperay)

After downloading, place the file into the `model/` directory:

```

XpeRay/
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îî‚îÄ‚îÄ adapter\_model.safetensors
‚îú‚îÄ‚îÄ inference.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ ...

```
> ‚ö†Ô∏è Make sure the file is named exactly `adapter_model.safetensors`, as expected by the code. Rename if necessary.
## Dataset

- **ROCO v2 Radiology**  
  Hugging Face Dataset: [`eltorio/ROCOv2-radiology`](https://huggingface.co/datasets/eltorio/ROCOv2-radiology)

## Training Configuration

- Batch size: 4  
- Accumulation steps: 8  
- Precision: bfloat16 (BF16)  
- Optimizer: `paged_adamw_8bit`  
- LoRA Config: `r=16`, `alpha=16`, no dropout  
- Sequence length: 2048  
- Checkpoints saved every 500 steps

Training is conducted on a single specified GPU with memory monitoring and device allocation handled via environment variables.

## Evaluation

- K-Fold cross-validation implemented in `test.py`
- Evaluation metrics:
  - BLEU
  - ROUGE-L
  - BERTScore
- Results logged in `results.txt`

## Example Usage

**Training**
```bash
python training.py
````

**Inference**

```bash
python inference.py --image_path path/to/image.png
```

## Model Loading

```python
from unsloth import FastVisionModel
model, tokenizer = FastVisionModel.from_pretrained("XpeRay")
```

## Requirements

* Python ‚â• 3.8
* PyTorch
* transformers
* datasets
* unsloth
* trl
* tqdm
* Pillow

## License

This project is for research and educational purposes only. Please verify your use case complies with any dataset and model licensing terms.

```
